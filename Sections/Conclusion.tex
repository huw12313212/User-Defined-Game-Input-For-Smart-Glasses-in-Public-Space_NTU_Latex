\section{Conclusion}

This paper explored user-defined game input for smart glasses beyond the capabilities of current sensors, and focused on gaming interaction in a public setting. We conducted a user-defined input study with 24 participants, each performing 17 common game control tasks using \emph{handheld}, \emph{touch} and \emph{non-touch} interaction methods with two form factors of smart glasses in a public cafe, which lead to a total of 2448 game inputs. Our results indicate that participants significantly preferred \emph{non-touch} interactions over \emph{handheld} interactions (3.81 vs 3.68, $p$ \textless 0.01). And the most frequently used body surface was the palm (51\%). Also, participants preferred using in-air gestures in front of the torso over gestures in front of the face(63\% vs 37\%) due to concerns with social acceptance and the hand fatigue. Furthermore, we indicated the mismatch between participants' preferred input methods and those supported by current smart glasses. Finally, we presented insight into users' mental models, and an understanding of implications for input technology and interface design. This work represents a necessary step in bringing glasses gaming closer to the hands and minds of smart glasses users.